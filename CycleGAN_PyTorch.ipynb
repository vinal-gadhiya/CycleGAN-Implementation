{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gizBRyTSkfup"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride, padding, use_activation=True):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, padding_mode='reflect')\n",
        "    self.inst_norm = nn.InstanceNorm2d(num_features=out_channels)\n",
        "    self.use_activation = use_activation\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.inst_norm(self.conv(x))\n",
        "    if self.use_activation:\n",
        "      x = F.relu(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "rAWWvLbGyBfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "    super().__init__()\n",
        "    self.conv1 = ConvBlock(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, use_activation=True)\n",
        "    self.conv2 = ConvBlock(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, use_activation=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    identity = x\n",
        "    return F.relu(torch.add(identity, self.conv2(self.conv1(x))))"
      ],
      "metadata": {
        "id": "FmaZFLqlrhOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FractionalConvBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding):\n",
        "    super().__init__()\n",
        "    self.frac_seq = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, output_padding=output_padding),\n",
        "        nn.InstanceNorm2d(num_features=out_channels),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.frac_seq(x)"
      ],
      "metadata": {
        "id": "lub38AGOrxL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, in_channels, num_of_residual_blocks):\n",
        "    super().__init__()\n",
        "    self.conv1 = ConvBlock(in_channels=in_channels, out_channels=64, kernel_size=7, stride=1, padding=3)\n",
        "    self.conv2 = ConvBlock(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1)\n",
        "    self.conv3 = ConvBlock(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    self.residual_blocks = []\n",
        "    self.num_of_residual_blocks = num_of_residual_blocks\n",
        "    for i in range(self.num_of_residual_blocks):\n",
        "      self.residual_blocks.append(ResidualBlock(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1))\n",
        "\n",
        "    self.residual_layers = nn.Sequential(\n",
        "        *self.residual_blocks\n",
        "    )\n",
        "\n",
        "    self.frac_conv1 = FractionalConvBlock(in_channels=256, out_channels=128, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
        "    self.frac_conv2 = FractionalConvBlock(in_channels=128, out_channels=64, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
        "    self.conv4 = ConvBlock(in_channels=64, out_channels=in_channels, kernel_size=7, stride=1, padding=3, use_activation=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.residual_layers(x)\n",
        "    x = self.frac_conv1(x)\n",
        "    x = self.frac_conv2(x)\n",
        "    x = torch.tanh(self.conv4(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "TlCypn5OycF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiscConvBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride, padding, use_instancenorm=True):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, padding_mode='reflect')\n",
        "    self.inst_norm = nn.InstanceNorm2d(num_features=out_channels)\n",
        "    self.use_instancenorm = use_instancenorm\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    if self.use_instancenorm:\n",
        "      x = self.inst_norm(x)\n",
        "    return F.leaky_relu(input=x, negative_slope=0.2)"
      ],
      "metadata": {
        "id": "RQvMMDtV8cEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, in_channels):\n",
        "    super().__init__()\n",
        "    self.disc_seq = nn.Sequential(\n",
        "        DiscConvBlock(in_channels=in_channels, out_channels=64, kernel_size=4, stride=2, padding=1, use_instancenorm=False),\n",
        "        DiscConvBlock(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1),\n",
        "        DiscConvBlock(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1),\n",
        "        DiscConvBlock(in_channels=256, out_channels=512, kernel_size=4, stride=1, padding=1),\n",
        "        nn.Conv2d(in_channels=512, out_channels=1, kernel_size=4, stride=1, padding=1, padding_mode='reflect'),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.disc_seq(x)"
      ],
      "metadata": {
        "id": "R2epk5Ji4pO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CycleGanDataset(Dataset):\n",
        "  def __init__(self, summer_root_dir, winter_root_dir):\n",
        "    self.summer_root_dir = summer_root_dir\n",
        "    self.winter_root_dir = winter_root_dir\n",
        "    self.summer_images = os.listdir(summer_root_dir)\n",
        "    self.winter_images = os.listdir(winter_root_dir)\n",
        "\n",
        "    self.length_dataset = max(len(self.summer_images), len(self.winter_images))\n",
        "    self.length_summer = len(self.summer_images)\n",
        "    self.length_winter = len(self.winter_images)\n",
        "\n",
        "    self.image_transform = T.ToTensor()\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.length_dataset\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    summer_image_path = os.path.join(self.summer_root_dir, self.summer_images[index % self.length_summer])\n",
        "    winter_image_path = os.path.join(self.winter_root_dir, self.winter_images[index % self.length_winter])\n",
        "\n",
        "    summer_image = self.image_transform(Image.open(summer_image_path))\n",
        "    winter_image = self.image_transform(Image.open(winter_image_path))\n",
        "\n",
        "    return summer_image, winter_image"
      ],
      "metadata": {
        "id": "dvFnUDHDB76x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CycleGanDataset(\"/content/drive/MyDrive/SummerToWinterCycleGANDataset/trainA\", \"/content/drive/MyDrive/SummerToWinterCycleGANDataset/trainB\")"
      ],
      "metadata": {
        "id": "GB04k1vyY9b_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, shuffle=True)"
      ],
      "metadata": {
        "id": "L6cdlXtia6Ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "pnOFivL_cpEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disc_summer = Discriminator(in_channels=3).to(device)\n",
        "disc_winter = Discriminator(in_channels=3).to(device)\n",
        "\n",
        "gen_summer = Generator(in_channels=3, num_of_residual_blocks=9).to(device)\n",
        "gen_winter = Generator(in_channels=3, num_of_residual_blocks=9).to(device)"
      ],
      "metadata": {
        "id": "2FRNRvItdHv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_disc = optim.Adam(\n",
        "    list(disc_summer.parameters()) + list(disc_winter.parameters()),\n",
        "    lr=2e-4,\n",
        "    betas=(0.5, 0.999)\n",
        ")"
      ],
      "metadata": {
        "id": "AIuJ1E5Tepjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_gen = optim.Adam(\n",
        "    list(gen_summer.parameters()) + list(gen_winter.parameters()),\n",
        "    lr=2e-4,\n",
        "    betas=(0.5, 0.999)\n",
        ")"
      ],
      "metadata": {
        "id": "xTMJHVlpg2Qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l1_loss = nn.L1Loss()\n",
        "mse = nn.MSELoss()"
      ],
      "metadata": {
        "id": "rAesKjEOg8jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 1\n",
        "for epoch in range(1, 201):\n",
        "  for idx, (summer_image, winter_image) in enumerate(train_dataloader):\n",
        "    summer_image = summer_image.to(device)\n",
        "    winter_image = winter_image.to(device)\n",
        "\n",
        "    fake_summer = gen_summer(winter_image)\n",
        "    disc_summer_real = disc_summer(summer_image)\n",
        "    disc_summer_fake = disc_summer(fake_summer.detach())\n",
        "    disc_summer_real_loss = mse(disc_summer_real, torch.ones_like(disc_summer_real))\n",
        "    disc_summer_fake_loss = mse(disc_summer_fake, torch.zeros_like(disc_summer_fake))\n",
        "    disc_summer_loss = disc_summer_real_loss + disc_summer_fake_loss\n",
        "\n",
        "    fake_winter = gen_winter(summer_image)\n",
        "    disc_winter_real = disc_winter(winter_image)\n",
        "    disc_winter_fake = disc_winter(fake_winter.detach())\n",
        "    disc_winter_real_loss = mse(disc_winter_real, torch.ones_like(disc_winter_real))\n",
        "    disc_winter_fake_loss = mse(disc_winter_fake, torch.zeros_like(disc_winter_fake))\n",
        "    disc_winter_loss = disc_winter_real_loss + disc_winter_fake_loss\n",
        "\n",
        "    disc_loss = (disc_summer_loss + disc_winter_loss)/2\n",
        "\n",
        "    optimizer_disc.zero_grad()\n",
        "    disc_loss.backward()\n",
        "    optimizer_disc.step()\n",
        "\n",
        "\n",
        "    disc_summer_fake = disc_summer(fake_summer)\n",
        "    disc_winter_fake = disc_winter(fake_winter)\n",
        "    loss_gen_summer = mse(disc_summer_fake, torch.ones_like(disc_summer_fake))\n",
        "    loss_gen_winter = mse(disc_winter_fake, torch.ones_like(disc_winter_fake))\n",
        "\n",
        "\n",
        "    cycle_summer = gen_summer(fake_winter)\n",
        "    cycle_winter = gen_winter(fake_summer)\n",
        "    cycle_summer_loss = l1_loss(summer_image, cycle_summer)\n",
        "    cycle_winter_loss = l1_loss(winter_image, cycle_winter)\n",
        "\n",
        "\n",
        "    gen_loss = (loss_gen_summer + loss_gen_winter + cycle_summer_loss*10 + cycle_winter_loss*10)\n",
        "\n",
        "    optimizer_gen.zero_grad()\n",
        "    gen_loss.backward()\n",
        "    optimizer_gen.step()\n",
        "\n",
        "    if idx % 200 == 0:\n",
        "      save_image(fake_summer, f\"/content/drive/MyDrive/teststow/summer_{count}_{idx}.jpeg\")\n",
        "      save_image(fake_winter, f\"/content/drive/MyDrive/teststow/winter_{count}_{idx}.jpeg\")\n",
        "      count += 1\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "      torch.save(gen_summer.state_dict(), f\"/content/drive/MyDrive/stow_checkpoints/summer_gen_epoch{epoch-1}.pth\")\n",
        "      torch.save(gen_winter.state_dict(), f\"/content/drive/MyDrive/stow_checkpoints/winter_gen_epoch{epoch-1}.pth\")\n",
        "      torch.save(disc_summer.state_dict(), f\"/content/drive/MyDrive/stow_checkpoints/summer_disc_epoch{epoch-1}.pth\")\n",
        "      torch.save(disc_winter.state_dict(), f\"/content/drive/MyDrive/stow_checkpoints/winter_disc_epoch{epoch-1}.pth\")"
      ],
      "metadata": {
        "id": "5-RAgcpahJfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ldjNIIQphwTs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}